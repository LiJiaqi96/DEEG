{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amazing-relations",
   "metadata": {},
   "source": [
    "# Deep learning with DEEG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-price",
   "metadata": {},
   "source": [
    "In this tutorial, we'll introduce how to use DEEG package to conduct deep learning (using PyTorch)  \n",
    "Here we use basic 1d CNN model as an example.  \n",
    "1. Data Loading  \n",
    "2. Quality check of data \n",
    "3. Model building  \n",
    "4. Load data with PyTorch\n",
    "5. Model training and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-conducting",
   "metadata": {},
   "source": [
    "**Step 1:** Load deeg and pytorch package, together necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cultural-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deeg\n",
    "import os\n",
    "import deeg\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-sullivan",
   "metadata": {},
   "source": [
    "**Step 2:** Load dataset. Here we used commonly-used DEAP dataset as an example.  \n",
    "After loading, the program will outout the shape of data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "utility-wells",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (1240, 40, 8064)\n",
      "Shape of labels: (1240, 4)\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory of your downloaded DEAP dataset below\n",
    "data_dir = \"/data1/ljq/datasets/EEG/DEAP/\"\n",
    "deap_dataset = deeg.load_DEAP(data_dir)\n",
    "deap_data, deap_label = deap_dataset[0], deap_dataset[1].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-currency",
   "metadata": {},
   "source": [
    "**Step 3:** Check whether the loaded dataset has missing values.  \n",
    "If missing value (NaN) occurs (\"check_result\" is not none), you may need to check your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "structured-craft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Data Quality Check ***\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "check_result = deeg.process.data_quality_check(deap_data)\n",
    "print(check_result=={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-administration",
   "metadata": {},
   "source": [
    "**Step 4:** Build deep learning model.  \n",
    "Here we use a built-in CNN model. The CNN model receives the signal from 40 channels simultaneously, and does convolutional calculation on 1d array. The output of CNN model is a vector, corresponding to the probability of each category.  \n",
    "Notice that we show GPU version here. You can also use CPU only by disable the \".cuda( )\" command.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-adolescent",
   "metadata": {},
   "source": [
    "First, let's set configurations for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gothic-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "batch_size = 8\n",
    "lr = 0.001\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-responsibility",
   "metadata": {},
   "source": [
    "Then, build the model and set arguments corresponding to DEAP dataset (i.e. 40 channels and 9 output categories)  \n",
    "And put the model to GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "awful-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeg.models.ConvNet(in_channel=40, num_classes=9)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-crystal",
   "metadata": {},
   "source": [
    "**Step 5:** Load data into PyTorch loaders  \n",
    "Here we just follow the workflow of PyTorch, using *Dataset* and *DataLoader*.  \n",
    "\n",
    "For illustration convenience, we use *sklearn* to split training and validation set. We strongly recommend that you complete this procedure by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alive-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeapDataset(Dataset):\n",
    "    def __init__(self, data_mat, label_mat, transform=None):\n",
    "        self.data_mat = data_mat\n",
    "        self.label_mat = label_mat\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_mat[idx,:]\n",
    "        label = self.label_mat[idx,...]   # label_mat can also be of dimension 1\n",
    "        return torch.tensor(data, dtype=torch.float), torch.tensor(label, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.label_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dried-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "deap_label_one = deap_label[:,0]   # DEAP has 4 categories of emotions, we focus on the first\n",
    "train_data, val_data, train_label, val_label = train_test_split(deap_data, deap_label_one-1, \n",
    "                                                                test_size=0.33, random_state=0)\n",
    "\n",
    "train_dataset = DeapDataset(train_data, train_label)\n",
    "val_dataset = DeapDataset(val_data, val_label)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, num_workers=4, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "usual-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, in_channel=40, num_classes=1):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channel, 32, kernel_size=5, stride=(1), padding=(2), bias=True),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size=5, stride=(1), padding=(2), bias=True),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=(1), padding=(1), bias=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(128 * 1008, 256, bias=True)\n",
    "        self.fc2 = nn.Linear(256, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-astronomy",
   "metadata": {},
   "source": [
    "**Step 6:** Set the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "according-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-license",
   "metadata": {},
   "source": [
    "**Step 7:** Model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "intellectual-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data, label in train_loader:\n",
    "        data, label = data.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.detach()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "def val(epoch, val_loader):                          \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in val_loader:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            out = model(data)\n",
    "            loss = criterion(out, label)\n",
    "            val_loss += loss.detach()*data.size(0)\n",
    "            preds = out.argmax(dim=1)\n",
    "            acc += torch.sum(preds==label)\n",
    "#             print(metric_acc(out_mask, mask), metric_acc(preds, label))\n",
    "    val_loss = val_loss/len(val_loader.dataset)\n",
    "    acc = acc/len(val_loader.dataset)\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f},  ACC: {:.6f}'.format(epoch, val_loss, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1,epochs+1):\n",
    "    train(epoch, train_loader)\n",
    "    val(epoch, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
